{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "X_VqEhTip1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "M7G43BXep1ck",
        "E6MkPsBcp1cl",
        "3MPXvC8up1cl",
        "Yfr_Vlr8HBkt",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitthakur1/Unsupervised-ML---Netflix-Movies-and-TV-Shows-Clustering/blob/main/Unsupervised_ML_Netflix_Movies_and_TV_Shows_Clustering_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Unsupervised ML - Netflix Movies and TV Shows Clustering\n",
        " By: Harshit Thakur\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA, Clustering, Content based recommender system, Unsupervised.\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary - Clustering Netflix Movies and TV Shows**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Netflix offers a vast and diverse library of movies and TV shows, making it essential to provide personalized recommendations to its users. Clustering is a powerful technique used to group similar content together, facilitating content discovery and user engagement. Here's an overview of how clustering is applied to Netflix content:\n",
        "\n",
        "Data Collection and Preparation:\n",
        "\n",
        "Netflix collects extensive metadata about each title, including genre, actors, directors, release year, and user interactions like viewing history and ratings.\n",
        "\n",
        "Feature Extraction:\n",
        "\n",
        "To apply clustering, relevant features are extracted from the dataset. These can include textual descriptions, user interactions, and metadata attributes.\n",
        "\n",
        "Text Preprocessing:\n",
        "\n",
        "Textual data, such as plot summaries and user reviews, undergo preprocessing, including tokenization, stop-word removal, and text vectorization using techniques like TF-IDF or word embeddings.\n",
        "\n",
        "Clustering Algorithms:\n",
        "\n",
        "Various clustering algorithms can be applied to group similar content. Common choices include K-Means, Hierarchical Clustering, and DBSCAN. The choice of algorithm depends on the dataset and specific goals.\n",
        "\n",
        "Distance or Similarity Metrics:\n",
        "\n",
        "Clustering relies on similarity or distance metrics, such as cosine similarity, Euclidean distance, or Jaccard similarity, to measure how similar or dissimilar content items are.\n",
        "\n",
        "Cluster Evaluation:\n",
        "\n",
        "To assess the quality of clusters, internal and external validation metrics, like silhouette score or Davies-Bouldin index, can be used. The choice of evaluation metric depends on the clustering algorithm.\n",
        "\n",
        "User Feedback Incorporation:\n",
        "\n",
        "Netflix continually collects user feedback, which can be used to improve clustering results. Feedback may include user ratings, watch history, and explicit likes and dislikes.\n",
        "\n",
        "Dynamic Clustering:\n",
        "\n",
        "Clusters need to be updated regularly to adapt to new content additions and changing user preferences. This requires periodic re-clustering and model retraining.\n",
        "\n",
        "Recommendation Systems:\n",
        "\n",
        "Once content items are clustered, they can be leveraged by recommendation systems. Users are presented with content from the same cluster they've previously enjoyed, enhancing their viewing experience.\n",
        "\n",
        "Personalization:\n",
        "\n",
        "Personalization is achieved by considering a user's history and preferences to make recommendations specific to their tastes and interests. Clustering enhances personalization by grouping content effectively.\n",
        "\n",
        "In summary, clustering Netflix movies and TV shows is an integral part of the recommendation engine, contributing to a more engaging and personalized user experience. It enables users to discover content that aligns with their preferences while helping Netflix manage and organize its vast library efficiently. The dynamic nature of content and user preferences requires ongoing monitoring and adaptation of clustering models to ensure the most relevant and up-to-date recommendations."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/harshitthakur1"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix is the world's largest online streaming service provider, with over 220 million subscribers as of 2022-Q2. It is crucial that they effectively cluster the shows that are hosted on their platform in order to enhance the user experience, thereby preventing subscriber churn.\n",
        "\n",
        "We will be able to understand the shows that are similar to and different from one another by creating clusters, which may be leveraged to offer the consumers personalized show suggestions depending on their preferences.\n",
        "\n",
        "The goal of this project is to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime as dt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re, string, unicodedata\n",
        "import nltk\n",
        "#import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "string.punctuation\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "52v9zXsPQB_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Alma projects/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv\",encoding=('ISO-8859-1'),low_memory=False)\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top 5 rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "n_rows, n_columns = df.shape\n",
        "print(f\"Number of columns: {n_columns} columns\\nNumber of rws: {n_rows} rows\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for duplicate records\n",
        "df.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no duplicated records in the dataset."
      ],
      "metadata": {
        "id": "e-Dqdw9RTNym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(df.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many missing values in director, cast, country, date_added, and rating columns.\n",
        "\n",
        "The missing values in the director, cast, and country attributes can be replaced with 'Unknown'\n",
        "\n",
        "10 records with missing values in the date_added column can be dropped.\n",
        "\n",
        "The missing values in rating can be imputed with its mode, since this attribute is discrete."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**show_id :** Unique ID for every Movie / Tv Show\n",
        "\n",
        "**type :** Identifier - A Movie or TV Show\n",
        "\n",
        "**title :** Title of the Movie / Tv Show\n",
        "\n",
        "**director :** Director of the Movie\n",
        "\n",
        "**cast :** Actors involved in the movie / show\n",
        "\n",
        "**country :** Country where the movie / show was produced\n",
        "\n",
        "**date_added :** Date it was added on Netflix\n",
        "\n",
        "**release_year :** Actual Releaseyear of the movie / show\n",
        "\n",
        "**rating :** TV Rating of the movie / show\n",
        "\n",
        "**duration :** Total Duration - in minutes or number of seasons\n",
        "\n",
        "**listed_in :** Genre\n",
        "\n",
        "**description:** The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling the missing values\n",
        "df[['director','cast','country']] = df[['director','cast','country']].fillna('Unknown')\n",
        "df['rating'] = df['rating'].fillna(df['rating'].mode()[0])\n",
        "df.dropna(axis=0, inplace = True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "gqfUjQyzWfSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully handled all the missing values in the dataset."
      ],
      "metadata": {
        "id": "YHq8-o0VWqOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top countries\n",
        "df.country.value_counts()\n"
      ],
      "metadata": {
        "id": "ikUEEosBfs_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Genre of shows\n",
        "df.listed_in.value_counts()"
      ],
      "metadata": {
        "id": "S2EJ4QRLgSP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some movies / TV shows that were filmed in multiple countries, have multiple genres associated with it.\n",
        "\n",
        "To simplify the analysis, let's consider only the primary country where that respective movie / TV show was filmed.\n",
        "\n",
        "Also, let's consider only the primary genre of the respective movie / TV show."
      ],
      "metadata": {
        "id": "Ue_kZN0Xh8LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing the primary country and primary genre to simplify the analysis\n",
        "df['country'] = df['country'].apply(lambda x: x.split(',')[0])\n",
        "df['listed_in'] = df['listed_in'].apply(lambda x: x.split(',')[0])"
      ],
      "metadata": {
        "id": "sz42btLoirSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contry in which a movie was produced\n",
        "df.country.value_counts()"
      ],
      "metadata": {
        "id": "JS78bPc-iwyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genre of shows\n",
        "df.listed_in.value_counts()"
      ],
      "metadata": {
        "id": "ZJgroG9Bi08N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Typecasting 'duration' from string to integer"
      ],
      "metadata": {
        "id": "CqJa1yd6kIv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the duration column, and changing the datatype to integer\n",
        "df['duration'] = df['duration'].apply(lambda x: int(x.split()[0]))"
      ],
      "metadata": {
        "id": "wQtZEkyNkNWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of seasons for tv shows\n",
        "df[df['type']=='TV Show'].duration.value_counts()"
      ],
      "metadata": {
        "id": "xkGAbCm0kQtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie length in minutes\n",
        "df[df['type']=='Movie'].duration.unique()"
      ],
      "metadata": {
        "id": "-sG8h8CwkUVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datatype of duration\n",
        "df.duration.dtype"
      ],
      "metadata": {
        "id": "p5dzaOpgkZi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Typecasting 'date_added' from string to datetime:"
      ],
      "metadata": {
        "id": "z4wO9n2ImbdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Typecasting 'date_added' from string to datetime\n",
        "df[\"date_added\"] = pd.to_datetime(df['date_added'])\n",
        "\n",
        "# first and last date on which a show was added on Netflix\n",
        "df.date_added.min(),df.date_added.max()"
      ],
      "metadata": {
        "id": "Vp5iCiWnme28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shows were added on Netflix between 1st January 2008 and 16th January 2021."
      ],
      "metadata": {
        "id": "z-g6z5gCnFND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new attributes month and year of date added\n",
        "\n",
        "df['month_added'] = df['date_added'].dt.month\n",
        "df['year_added'] = df['date_added'].dt.year\n",
        "df.drop('date_added', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "zVJDcXgnnIrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rating:"
      ],
      "metadata": {
        "id": "zCT50HEEnpQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Age ratings for shows in the dataset\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(x='rating',data=df)"
      ],
      "metadata": {
        "id": "1YjUL2Dbnrm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest number of shows on Netflix are rated by TV-MA, followed by TV-14 and TV-PG"
      ],
      "metadata": {
        "id": "VT89bPJlqEZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Age ratings\n",
        "df.rating.unique()"
      ],
      "metadata": {
        "id": "054Vvy4ioIzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the values in the rating column\n",
        "rating_map = {'TV-MA':'Adults',\n",
        "              'R':'Adults',\n",
        "              'PG-13':'Teens',\n",
        "              'TV-14':'Young Adults',\n",
        "              'TV-PG':'Older Kids',\n",
        "              'NR':'Adults',\n",
        "              'TV-G':'Kids',\n",
        "              'TV-Y':'Kids',\n",
        "              'TV-Y7':'Older Kids',\n",
        "              'PG':'Older Kids',\n",
        "              'G':'Kids',\n",
        "              'NC-17':'Adults',\n",
        "              'TV-Y7-FV':'Older Kids',\n",
        "              'UR':'Adults'}\n",
        "\n",
        "df['rating'].replace(rating_map, inplace = True)\n",
        "df['rating'].unique()"
      ],
      "metadata": {
        "id": "Gso6Q7igorLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age ratings for shows in the dataset\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(x='rating',data=df)"
      ],
      "metadata": {
        "id": "avhVhW_PptB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Around 50% of shows on Netflix are produced for adult audience. Followed by young adults, older kids and kids. Netflix has the least number of shows that are specifically produced for teenagers than other age groups."
      ],
      "metadata": {
        "id": "N_EEWYTqpyk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis(EDA)**"
      ],
      "metadata": {
        "id": "gcIskf000Rub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Univatiate Analysis:**"
      ],
      "metadata": {
        "id": "rnEp5mWo0CHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Movies and TV Shows in the dataset\n",
        "plt.figure(figsize=(7,7))\n",
        "df.type.value_counts().plot(kind='pie',autopct='%1.2f%%')\n",
        "plt.ylabel('')\n",
        "plt.title('Movies and TV Shows in the dataset')"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are more movies (69.14%) than TV shows (30.86%) in the dataset."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 directors in the dataset\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 directors by number of shows directed')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Raul Campos and Jan Suter together have directed 18 movies / TV shows, higher than anyone in the dataset."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 countries with the highest number movies / TV shows in the dataset\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['country']=='Unknown')].country.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title(' Top 10 countries with the highest number of shows')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest number of movies / TV shows were based out of the US, followed by India and UK."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_3 = df.country.value_counts().nlargest(3).sum() / len(df) * 100\n",
        "\n",
        "# Percent share of movies/TV shows by the top 10 countries\n",
        "top_10 = df.country.value_counts().nlargest(10).sum() / len(df) * 100\n",
        "\n",
        "# Data\n",
        "countries = ['Top 3', 'Top 10']\n",
        "percentages = [top_3, top_10]\n",
        "\n",
        "# Create a bar chart\n",
        "plt.bar(countries, percentages, color=['blue', 'green'])\n",
        "plt.xlabel('Countries')\n",
        "plt.ylabel('Percentage Share (%)')\n",
        "plt.title('Percentage Share of Movies/TV Shows by Countries')\n",
        "# Add percentage labels to the bars\n",
        "for i, percentage in enumerate(percentages):\n",
        "    plt.text(i, percentage, f'{percentage:.2f}%', ha='center', va='bottom')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h9KAIVXLs92k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top 3 countries together account for about 56% of all movies and TV shows in the dataset.\n",
        "\n",
        "This value increases to about 78% for top ten countries."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the year in which the movie / tv show was released\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['release_year'])\n",
        "plt.title('distribution by released year')"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has greater number of new movies / TV shows than the old ones."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 genres\n",
        "plt.figure(figsize=(10,5))\n",
        "df.listed_in.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 genres')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dramas is the most popular genre followed by comedies and documentaries."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Share of the top 3 genres\n",
        "top_3_genres = df.listed_in.value_counts().nlargest(3).sum() / len(df) * 100\n",
        "\n",
        "# Share of the top 10 genres\n",
        "top_10_genres = df.listed_in.value_counts().nlargest(10).sum() / len(df) * 100\n",
        "\n",
        "# Data\n",
        "genre_categories = ['Top 3 Genres', 'Top 10 Genres']\n",
        "genre_percentages = [top_3_genres, top_10_genres]\n",
        "\n",
        "# Create a bar chart\n",
        "plt.bar(genre_categories, genre_percentages, color=['blue', 'green'])\n",
        "plt.xlabel('Genre Categories')\n",
        "plt.ylabel('Percentage Share (%)')\n",
        "plt.title('Percentage Share of Top Genres')\n",
        "\n",
        "# Add percentage labels to the bars\n",
        "for i, percentage in enumerate(genre_percentages):\n",
        "    plt.text(i, percentage, f'{percentage:.2f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These three genres account for about 41% of all movies and TV shows.\n",
        "This value increases to about 82% for top 10 genres."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of shows added on different months\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = sns.countplot(data=df, x='month_added')\n",
        "plt.title('Shows added each month over the years')\n",
        "ax.set_xticklabels(['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], rotation=30)\n",
        "plt.xlabel('Month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a countplot because it is a suitable chart for visualizing the distribution of categorical data, which is the case in this scenario. The data involves counts of shows added each month, and a countplot is effective for displaying the frequency or count of each category (in this case, each month) on the x-axis"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Over the years a greater number of shows were added in the months of October, November, December, and January.**"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of shows added over the years\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = sns.countplot(data=df, x='year_added')\n",
        "plt.title('Number of shows added each year')\n",
        "plt.xlabel('Year')"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix continuous to add more shows on its platform over the years.\n",
        "\n",
        "There is a decrease in the number of shows added in the year 2020, which might be attributed to the covid-19-induced lockdowns, which halted the creation of shows.\n",
        "\n",
        "We have Netflix data only up to 16th January 2021, hence there are less movies added in this year."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of shows on Netflix for different age groups\n",
        "plt.figure(figsize=(10,5))\n",
        "df.rating.value_counts().plot(kind='barh')\n",
        "plt.title('Number of shows on Netflix for different age groups')"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of the shows on Netflix are catered to the needs of adult and young adult population."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bivariate analysis:**"
      ],
      "metadata": {
        "id": "8_ewqaS4z4kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of shows released each year since 2008\n",
        "order = range(2008,2022)\n",
        "plt.figure(figsize=(10,5))\n",
        "p = sns.countplot(x='release_year',data=df, hue='type',\n",
        "                  order = order)\n",
        "plt.title('Number of shows released each year since 2008 that are on Netflix')\n",
        "plt.xlabel('')\n",
        "for i in p.patches:\n",
        "  p.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over the years, Netflix has consistently focused on adding more shows in its platform.\n",
        "\n",
        "Though there was a decrease in the number of movies added in 2020, this pattern did not exist in the number of TV shows added in the same year.\n",
        "\n",
        "This might signal that Netflix is increasingly concentrating on introducing more TV series to its platform rather than movies."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seasons in each TV show\n",
        "plt.figure(figsize=(10,5))\n",
        "p = sns.countplot(x='duration',data=df[df['type']=='TV Show'])\n",
        "plt.title('Number of seasons per TV show distribution')\n",
        "\n",
        "for i in p.patches:\n",
        "  p.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of TV shows with just 1 season\n",
        "percentage = (len(df[(df['type'] == 'TV Show') & (df['duration'] == 1)]) / len(df[df['type'] == 'TV Show'])) * 100\n",
        "\n",
        "# Data for the bar plot\n",
        "categories = ['TV Shows with 1 Season', 'Other TV Shows']\n",
        "values = [percentage, 100 - percentage]\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(categories, values, color=['blue', 'gray'])\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.title('Percentage of TV Shows with Just 1 Season')\n",
        "\n",
        "# Add percentage values on top of the bars\n",
        "for bar, value in zip(bars, values):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, value, f'{value:.2f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9G4Ve-Ht3E-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TV series in the dataset have up to 16 seasons, however the bulk of them only have one. This might mean that the majority of TV shows has only recently begun, and that further seasons are on the way.\n",
        "\n",
        "There are very few TV shows that have more than 8 seasons."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# length of movie analysis\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(x='duration',data=df[df['type']=='Movie'])\n",
        "plt.title('Movie duration distribution')\n",
        "# Movie statistics\n",
        "df[df['type']== 'Movie'].duration.describe()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The length of a movie may range from 3 min to 312 minutes, and the distribution is almost normally distributed."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chart - 14"
      ],
      "metadata": {
        "id": "QB82RlYGQ4Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average movie length over the years\n",
        "plt.figure(figsize=(10,5))\n",
        "df[df['type']=='Movie'].groupby('release_year')['duration'].mean().plot(kind='line')\n",
        "plt.title('Average movie length over the years')\n",
        "plt.ylabel('Length of movie in minutes')\n",
        "plt.xlabel('Year')\n",
        "# Movie release year statistics\n",
        "df[df['type']== 'Movie'].release_year.describe()"
      ],
      "metadata": {
        "id": "nrFB2UNLRFeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "A9KWCx0xRUts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has several movies on its site, including those that were released in way back 1942.\n",
        "\n",
        "As per the plot, movies made in the 1940s had a fairly short duration on average.\n",
        "\n",
        "On average, movies made in the 1960s have the longest movie length.\n",
        "The average length of a movie has been continuously decreasing since the 2000s."
      ],
      "metadata": {
        "id": "K4VP0-zkRlTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart - 15"
      ],
      "metadata": {
        "id": "-ag2IzzgR2of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 genre for movies\n",
        "plt.figure(figsize=(10,5))\n",
        "df[df['type']=='Movie'].listed_in.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 genres for movies')"
      ],
      "metadata": {
        "id": "zgM0oykbR-N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dramas, comedies, and documentaries are the most popular genre for the movies on Netflix."
      ],
      "metadata": {
        "id": "G45RjE97SNVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart - 16"
      ],
      "metadata": {
        "id": "VLr0C7YqSz4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 genre for tv shows\n",
        "plt.figure(figsize=(10,5))\n",
        "df[df['type']=='TV Show'].listed_in.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 genres for TV Shows')"
      ],
      "metadata": {
        "id": "kkSp28ZnS0mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "International, crime, and kids are the most popular genre for TV shows on Netflix."
      ],
      "metadata": {
        "id": "SxnRAvjCTE3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart - 17"
      ],
      "metadata": {
        "id": "rwR-vPIQW8dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 movie directors\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='Movie')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 movie directors')"
      ],
      "metadata": {
        "id": "5tGacvqlW9Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Raul Campos and Jan Suter have togather directed in 18 movies, higher than anyone yet.\n",
        "\n",
        "This is followed by Marcus Roboy, Jay Karas, and Cathy Gracia-Molina"
      ],
      "metadata": {
        "id": "bd02pM_JXSvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart - 18"
      ],
      "metadata": {
        "id": "P80Y4b9KXVPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 TV show directors\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='TV Show')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 TV show directors')"
      ],
      "metadata": {
        "id": "XirOiwYeXpYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alastair Fothergill has directed three TV shows, the most of any director.\n",
        "\n",
        "Only six directors have directed more than one television show."
      ],
      "metadata": {
        "id": "ALannE1eYeOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart - 19"
      ],
      "metadata": {
        "id": "8I2cW0N1ZTvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top actors for movies\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['cast']=='Unknown') & (df['type']=='Movie')].cast.value_counts().nlargest(5).plot(kind='barh')\n",
        "plt.title('Actors who have appeared in highest number of movies')"
      ],
      "metadata": {
        "id": "fe_mie_oZUSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Samuel West has appeared in 10 movies, followed by Jeff Dunham with 7 movies."
      ],
      "metadata": {
        "id": "FzQhYbq7aBzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart - 20"
      ],
      "metadata": {
        "id": "gvzRS0aRaPcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top actors for TV shows\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['cast']=='Unknown') & (df['type']=='TV Show')].cast.value_counts().nlargest(5).plot(kind='barh')\n",
        "plt.title('Actors who have appeared in highest number of TV shows')"
      ],
      "metadata": {
        "id": "Y_77UyuMaP9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "David Attenborough has appeared in 13 TV shows, followed by Michela Luci, Jamie Watson, Anna Claire Bartlam, Dante Zee, Eric Peterson with 4 TV shows."
      ],
      "metadata": {
        "id": "Z2TuiCAJaero"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a wordcloud"
      ],
      "metadata": {
        "id": "rnymzVusa0-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "# iterate through the csv file\n",
        "for val in df.description.values:\n",
        "\n",
        "    # typecaste each val to string\n",
        "    val = str(val)\n",
        "\n",
        "    # split the value\n",
        "    tokens = val.split()\n",
        "\n",
        "    # Converts each token into lowercase\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "\n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 700, height = 700,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (10,5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "m1uHo5IIa1kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some keywords in Netflix show descriptions: life, family, new, love, young, world, group, death, man, woman, murder, son, girl, documentary, secret."
      ],
      "metadata": {
        "id": "7GFcm_fmbIJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling Approach:\n",
        "\n",
        "Select the attributes based on which you want to cluster the shows\n",
        "\n",
        "Text preprocessing: Remove all non-ascii characters, stopwords and punctuation marks, convert all textual data to lowercase.\n",
        "\n",
        "Lemmatization to generate a meaningful word out of corpus of words\n",
        "\n",
        "Tokenization of corpus\n",
        "\n",
        "Word vectorization\n",
        "\n",
        "Dimensionality reduction\n",
        "\n",
        "Use different algorithms to cluster the movies, obtain the optimal number of clusters using different techniques\n",
        "\n",
        "Build optimal number of clusters and visualize the contents of each cluster using wordclouds."
      ],
      "metadata": {
        "id": "SW5aXprPpIE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Using the original dataset for clustering since\n",
        "# it does not require handling missing values\n",
        "df1 = df.copy()\n",
        "df1.fillna('',inplace=True)\n",
        "df1"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Combining all the clustering attributes into a single column\n",
        "\n",
        "df1['clustering_attributes'] = (df1['director'] + ' ' +\n",
        "                                df1['cast'] +' ' +\n",
        "                                df1['country'] +' ' +\n",
        "                                df1['listed_in'] +' ' +\n",
        "                                df1['description'])\n",
        "\n",
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully added all the necessary data into a single column"
      ],
      "metadata": {
        "id": "igXqWOJKw-rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Removing non-ASCII characters:"
      ],
      "metadata": {
        "id": "DlUWkUYkyOdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove non-ascii characters\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Function to remove non-ASCII characters\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "# remove non-ascii characters\n",
        "df1['clustering_attributes'] = remove_non_ascii(df1['clustering_attributes'])\n",
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "UQW1BloMyH9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully removed all non-ascii characters from the corpus."
      ],
      "metadata": {
        "id": "gEKteLcc0Vg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing/Removing Stopwords"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the stopwords from nltk library\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')\n",
        "# displaying the stopwords\n",
        "np.array(sw)\n",
        "# function to remove stop words\n",
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)\n",
        "# Removing stop words\n",
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(stopwords)\n",
        "print(df1['clustering_attributes'][40])\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)\n",
        "# Removing punctuation marks\n",
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(remove_punctuation)\n",
        "print(df1['clustering_attributes'][40])"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Lemmatization\n",
        "\n",
        "Lemmatization is a text normalization process that involves reducing words to their base or root form, known as a \"lemma.\" The goal of lemmatization is to reduce words to a common base or root form so that different inflected forms of a word are treated as the same word. This helps in text analysis and natural language processing tasks by simplifying the vocabulary and improving the accuracy of text analysis.\n",
        "\n",
        "For example, in lemmatization:\n",
        "\n",
        "The word \"running\" would be reduced to its lemma \"run.\""
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to lemmatize the corpus\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "# Lemmatization\n",
        "df1['clustering_attributes'] = lemmatize_verbs(df1['clustering_attributes'])\n",
        "print(df1['clustering_attributes'][40])"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TweetTokenizer\n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "# Define a function to tokenize strings and handle non-string elements\n",
        "def tokenize_text(x):\n",
        "    if isinstance(x, str):\n",
        "        return tokenizer.tokenize(x)\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "# Apply the tokenization function to the 'clustering_attributes' column\n",
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(tokenize_text)\n",
        "\n",
        "# Print a sample of the tokenized data\n",
        "sample_size = 5\n",
        "sample = df1['clustering_attributes'].sample(sample_size)\n",
        "for tokens in sample:\n",
        "    if isinstance(tokens, list):\n",
        "        print(tokens)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have chosen to use TF-IDF vectorization for several reasons. Firstly, TF-IDF considers the importance of each term in the context of the document and the entire corpus. This enables me to focus on the most relevant terms within each document, making it an ideal choice for tasks that require identifying key terms or concepts.\n",
        "\n",
        "Secondly, by combining TF-IDF with stop-word removal, I can eliminate common and less informative words, which further enhances the quality of the vectorization. This is crucial for ensuring that the resulting feature representation is content-bearing and meaningful.\n",
        "\n",
        "Thirdly, I've limited the dimensionality of the vectorization using the max_features parameter to make clustering and other NLP tasks more efficient, especially when dealing with a large vocabulary.\n",
        "\n",
        "In addition, TF-IDF provides normalized values, making it suitable for comparing and clustering documents of varying lengths. This normalization ensures that longer documents do not have an unfair advantage due to their length."
      ],
      "metadata": {
        "id": "sJ-0wP2gNVQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "# clustering tokens saved in a variable\n",
        "clustering_data = df1['clustering_attributes']\n",
        "# Tokenization\n",
        "def identity_tokenizer(text):\n",
        "    return text\n",
        "\n",
        "# Using TFIDF vectorizer to vectorize the corpus\n",
        "# max features = 20000 to prevent system from crashing\n",
        "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False,max_features = 20000)\n",
        "X = tfidf.fit_transform(clustering_data)\n",
        "X\n",
        "# Shape of X\n",
        "X.shape\n",
        "# data type of vector\n",
        "type(X)\n",
        "# convert X into array form for clustering\n",
        "X = X.toarray()\n",
        "print(X)\n",
        "print(type(X))\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of clustering Netflix movies and TV shows, dimensionality reduction can be beneficial for several reasons:\n",
        "\n",
        "High Dimensionality of Features: Netflix datasets often have a large number of features, which may represent various attributes, metadata, or user-related information. High dimensionality can lead to computational challenges and slower clustering algorithms. Dimensionality reduction can simplify the dataset, making it more manageable for clustering.\n",
        "\n",
        "Reduced Noise: Some features in Netflix datasets may not be relevant for clustering and can introduce noise into the analysis. Dimensionality reduction techniques can help filter out less important features, focusing on the most informative ones.\n",
        "\n",
        "Improved Interpretability: Dimensionality reduction can aid in making sense of the dataset and the clusters formed. By visualizing the data in a lower-dimensional space, patterns and similarities among movies and TV shows become more apparent, contributing to better cluster interpretability.\n",
        "\n",
        "Enhanced Cluster Quality: Clustering algorithms may perform better when the dimensionality of the data is reduced. Reducing the number of features can lead to more coherent and well-separated clusters.\n",
        "\n",
        "Efficient Computation: Dimensionality reduction can speed up the clustering process, making it more efficient. This is particularly valuable when working with a vast amount of Netflix content."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have utilized Principal Component Analysis (PCA) as the dimensionality reduction technique for the dataset. PCA is a popular choice for several reasons. Firstly, PCA is effective at reducing the dimensionality of the data while retaining the most important information. It does this by identifying the principal components, which are linear combinations of the original features, and arranging them in descending order of variance. By retaining a subset of these components, I can reduce the dataset's dimensionality while preserving as much of the data's variance as possible."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More than 80% of the variance is explained just by 4000 components.\n",
        "\n",
        "Hence to simplify the model, and reduce dimensionality, we can take the top 4000 components, which will still be able to capture more than 80% of variance."
      ],
      "metadata": {
        "id": "1VL9_utdkf6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using PCA to reduce dimensionality\n",
        "pca = PCA(n_components=100, random_state=42)  # Adjust the number of components as needed\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained variance for different number of components\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - Cumulative explained variance vs number of components')\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')"
      ],
      "metadata": {
        "id": "wShf1Lv9c7Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "x_pca = pca.transform(X)\n",
        "# shape of transformed vectors\n",
        "x_pca.shape"
      ],
      "metadata": {
        "id": "Ngv17ECwnejA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1(K-Means Clustering)"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow method to find the optimal value of k\n",
        "wcss=[]\n",
        "for i in range(1,31):\n",
        "  kmeans = KMeans(n_clusters=i,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  wcss_iter = kmeans.inertia_\n",
        "  wcss.append(wcss_iter)\n",
        "\n",
        "number_clusters = range(1,31)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(number_clusters,wcss)\n",
        "plt.title('The Elbow Method - KMeans clustering')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sum of squared distance between each point and the centroid in a cluster (WCSS) decreases with the increase in the number of clusters."
      ],
      "metadata": {
        "id": "eMVGjQZapuu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Silhouette score for different umber of clusters\n",
        "range_n_clusters = range(2,31)\n",
        "silhouette_avg = []\n",
        "for num_clusters in range_n_clusters:\n",
        "  # initialize kmeans\n",
        "  kmeans = KMeans(n_clusters=num_clusters,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  cluster_labels = kmeans.labels_\n",
        "\n",
        "  # silhouette score\n",
        "  silhouette_avg.append(silhouette_score(x_pca, cluster_labels))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range_n_clusters,silhouette_avg)\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x3UQZlcapvxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest Silhouette score is obtained for 6 clusters."
      ],
      "metadata": {
        "id": "7jIEHVqxqeRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the data into 19 clusters\n",
        "kmeans = KMeans(n_clusters=6,init='k-means++',random_state=33)\n",
        "kmeans.fit(x_pca)"
      ],
      "metadata": {
        "id": "Q4YHyrJgqe-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(x_pca, kmeans.labels_)\n",
        "\n",
        "print((kmeans_distortion,kmeans_silhouette_score))"
      ],
      "metadata": {
        "id": "_dVm8d1grH57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df1['kmeans_cluster'] = kmeans.labels_\n",
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='kmeans_cluster',data=df1, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "lDK-595crqHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def kmeans_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df1[df1['kmeans_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "       # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                  stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "  # plot the WordCloud image\n",
        "  plt.figure(figsize = (10,5), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "JRP5eOO1tiV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 0\n",
        "kmeans_worldcloud(0)"
      ],
      "metadata": {
        "id": "9jl3EJICynBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster 0: life, new, family, friend, save, help, discover, home, teen"
      ],
      "metadata": {
        "id": "Aowo4-eQyxix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 1\n",
        "kmeans_worldcloud(1)"
      ],
      "metadata": {
        "id": "8kYZXAcUy6x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster 1: life, love, family, father, young, girl, man, woman, friend, daughter"
      ],
      "metadata": {
        "id": "lD4W9Yz5zB5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 2\n",
        "kmeans_worldcloud(2)\n",
        "# Keywords observed in cluster 2: young, world, girl, mysterious, humanity, life, student, school, battle, demon, force\n",
        "\n",
        "# Wordcloud for cluster 3\n",
        "kmeans_worldcloud(3)\n",
        "# Keywords observed in cluster 3: love, life, family, romance, crime, murder, world, adventure\n",
        "\n",
        "# Wordcloud for cluster 4\n",
        "kmeans_worldcloud(4)\n",
        "# Keywords observed in cluster 4: comedian, special, stand, comic, stage, sex, joke\n",
        "\n",
        "# Wordcloud for cluster 5\n",
        "kmeans_worldcloud(5)\n",
        "# Keywords observed in cluster 5: documentary, world, life, filmmaker, american, life"
      ],
      "metadata": {
        "id": "8wajsIYZzKov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2(Hierarchical clustering)"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a dendogram to decide on the number of clusters\n",
        "plt.figure(figsize=(10, 7))\n",
        "dend = shc.dendrogram(shc.linkage(x_pca, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 3.8, color='r', linestyle='--')"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At a distance of 3.8 units, 12 clusters can be built using the agglomerative clustering algorithm."
      ],
      "metadata": {
        "id": "xrLqvv9M2j4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=12, affinity='euclidean', linkage='ward')\n",
        "hierarchical.fit_predict(x_pca)"
      ],
      "metadata": {
        "id": "qZF9KTJR2wfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df1['hierarchical_cluster'] = hierarchical.labels_\n",
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='hierarchical_cluster',data=df1, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "40wwrZRU236X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 12 clusters using the Agglomerative (hierarchical) clustering algorithm."
      ],
      "metadata": {
        "id": "oAbWMfhH4cE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def hierarchical_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df1[df1['hierarchical_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "\n",
        "      # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                  stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)\n",
        "\n",
        "  # plot the WordCloud image\n",
        "  plt.figure(figsize = (10,5), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "nYbG0QF_3OVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 0\n",
        "hierarchical_worldcloud(0)\n",
        "#Keywords observed in cluster 0: life, new, find, family, save, friend, young, teen, adventure\n",
        "\n",
        "# Wordcloud for cluster 1\n",
        "hierarchical_worldcloud(1)\n",
        "#Keywords observed in cluster 1: love, family, life, student, romance, school, woman, master, father\n",
        "\n",
        "# Wordcloud for cluster 2\n",
        "hierarchical_worldcloud(2)\n",
        "#Keywords observed in cluster 2: life, new, series, crime, world, murder, history, detective\n",
        "\n",
        "# Wordcloud for cluster 3\n",
        "hierarchical_worldcloud(3)\n",
        "#Keywords observed in cluster 3: family, life, love, friend, teen, woman, man, young, world, wedding, secret\n",
        "\n",
        "# Wordcloud for cluster 4\n",
        "hierarchical_worldcloud(4)\n",
        "#Keywords observed in cluster 4: documentary, music, world, team, interview,history, family, career, battle, death\n",
        "\n",
        "# Wordcloud for cluster 5\n",
        "hierarchical_worldcloud(5)\n",
        "#Keywords observed in cluster 5: family, life, mexico, young, new, woman, man, secret, spain, death, singer\n",
        "\n",
        "# Wordcloud for cluster 6\n",
        "hierarchical_worldcloud(6)\n",
        "#Keywords observed in cluster 6: young, life, girl, world, friend, mysterious, demon, student, school, father\n",
        "\n",
        "# Wordcloud for cluster 7\n",
        "hierarchical_worldcloud(7)\n",
        "#Keywords observed in cluster 7: love, life, woman, new, student, family, korea, secret, detective, young\n",
        "\n",
        "# Wordcloud for cluster 8\n",
        "hierarchical_worldcloud(8)\n",
        "#Keywords observed in cluster 8: woman, man life, egypt, wealthy, money, young, love, revolution, struggling\n",
        "\n",
        "# Wordcloud for cluster 9\n",
        "hierarchical_worldcloud(9)\n",
        "#Keywords observed in cluster 9: comedian, stand, life, comic, special, show, live, star, stage, hilarious, stories\n",
        "\n",
        "# Wordcloud for cluster 10\n",
        "hierarchical_worldcloud(10)\n",
        "#Keywords observed in cluster 10: animal, nature, explore, planet, species, survive, natural, life, examine, earth\n",
        "\n",
        "# Wordcloud for cluster 11\n",
        "hierarchical_worldcloud(11)\n",
        "#Keywords observed in cluster 11: love, man, woman, india, father, friend, girl, mumbai, city, learn, young"
      ],
      "metadata": {
        "id": "CWxzKdof3cJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Content based recommender system**"
      ],
      "metadata": {
        "id": "c5ZobX3P7CnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can build a simple content based recommender system based on the similarity of the shows.\n",
        "\n",
        "If a person has watched a show on Netflix, the recommender system must be able to recommend a list of similar shows that s/he likes.\n",
        "\n",
        "To get the similarity score of the shows, we can use cosine similarity\n",
        "The similarity between two vectors (A and B) is calculated by taking the dot product of the two vectors and dividing it by the magnitude value as shown in the equation below. We can simply say that the CS score of two vectors increases as the angle between them decreases.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g912kfs67K24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# defining a new df for building a recommender system\n",
        "recommender_df = df1.copy()\n",
        "# Changing the index of the df from show id to show title\n",
        "recommender_df['show_id'] = recommender_df.index\n",
        "# converting tokens to string\n",
        "def convert(lst):\n",
        "  return ' '.join(lst)\n",
        "\n",
        "recommender_df['clustering_attributes'] = recommender_df['clustering_attributes'].apply(lambda x: convert(x))\n",
        "# setting title of movies/Tv shows as index\n",
        "recommender_df.set_index('title',inplace=True)\n",
        "# Count vectorizer\n",
        "CV = CountVectorizer()\n",
        "converted_matrix = CV.fit_transform(recommender_df['clustering_attributes'])\n",
        "# Cosine similarity\n",
        "# Calculate the cosine similarity matrix\n",
        "cosine_similarity = cosine_similarity(converted_matrix)\n",
        "cosine_similarity.shape\n",
        "# Developing a function to get 10 recommendations for a show\n",
        "indices = pd.Series(recommender_df.index)\n",
        "\n",
        "def recommend_10(title, cosine_sim = cosine_similarity):\n",
        "  try:\n",
        "    recommend_content = []\n",
        "    idx = indices[indices == title].index[0]\n",
        "    series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "    top10 = list(series.iloc[1:11].index)\n",
        "    # list with the titles of the best 10 matching movies\n",
        "    for i in top10:\n",
        "      recommend_content.append(list(recommender_df.index)[i])\n",
        "    print(\"If you liked '\"+title+\"', you may also enjoy:\\n\")\n",
        "    return recommend_content\n",
        "\n",
        "  except:\n",
        "    return 'Invalid Entry'\n",
        "\n",
        "# Recommendations for 'A Man Called God'\n",
        "recommend_10('A Man Called God')\n",
        "\n",
        "# Recommendations for 'Stranger Things'\n",
        "recommend_10('Stranger Things')\n",
        "\n",
        "# Recommendations for 'Peaky Blinders'\n",
        "recommend_10('Peaky Blinders')\n",
        "\n",
        "# Recommendations for 'Lucifer'\n",
        "recommend_10('Lucifer')\n",
        "\n",
        "# Recommendations for 'one piece'\n",
        "recommend_10('one piece')"
      ],
      "metadata": {
        "id": "cYbc0u-O76bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invalid because the show 'one piece' is not available on Netflix."
      ],
      "metadata": {
        "id": "3j0mKAtUBvH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we worked on a text clustering problem wherein we had to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other.\n",
        "\n",
        "The dataset contained about 7787 records, and 11 attributes.\n",
        "\n",
        "We began by dealing with the dataset's missing values and doing exploratory data analysis (EDA).\n",
        "\n",
        "It was found that Netflix hosts more movies than TV shows on its platform, and the total number of shows added on Netflix is growing exponentially. Also, majority of the shows were produced in the United States, and the majority of the shows on Netflix were created for adults and young adults age group.\n",
        "\n",
        "It was decided to cluster the data based on the attributes: director, cast, country, genre, and description. The values in these attributes were tokenized, preprocessed, and then vectorized using TFIDF vectorizer.\n",
        "\n",
        "Through TFIDF Vectorization, we created a total of 20000 attributes.\n",
        "\n",
        "We used Principal Component Analysis (PCA) to handle the curse of dimensionality. 4000 components were able to capture more than 80% of variance, and hence, the number of components were restricted to 4000.\n",
        "\n",
        "We first built clusters using the k-means clustering algorithm, and the optimal number of clusters came out to be 6. This was obtained through the elbow method and Silhouette score analysis.\n",
        "\n",
        "Then clusters were built using the Agglomerative clustering algorithm, and the optimal number of clusters came out to be 12. This was obtained after visualizing the dendrogram.\n",
        "\n",
        "A content based recommender system was built using the similarity matrix obtained after using cosine similarity. This recommender system will make 10 recommendations to the user based on the type of show they watched."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}